{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8fMYscczLXC"
      },
      "source": [
        "# Clone the repo\n",
        "Get the repo and submodules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5sH_dEAzLXF",
        "outputId": "46f029a3-a872-4da3-c39e-2e8c398a1cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7-logo'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 188 (delta 57), reused 73 (delta 25), pack-reused 71 (from 1)\u001b[K\n",
            "Receiving objects: 100% (188/188), 78.76 MiB | 23.67 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nuwandda/yolov7-logo.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obavJ9wPzLXG"
      },
      "source": [
        "Download submodules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oNQOvjkzLXG",
        "outputId": "f768c21f-b1c3-4d3b-faf8-8b5374177aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7-logo\n",
            "Submodule 'src/yolov7' (https://github.com/WongKinYiu/yolov7.git) registered for path 'src/yolov7'\n",
            "Cloning into '/content/yolov7-logo/src/yolov7'...\n",
            "Submodule path 'src/yolov7': checked out '8c0bf3f78947a2e81a1d552903b4934777acfa5f'\n"
          ]
        }
      ],
      "source": [
        "%cd yolov7-logo/\n",
        "!git submodule update --init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKSV5HyFzLXH"
      },
      "source": [
        "Install the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "crrlToAtzLXH",
        "outputId": "56fdcceb-6c88-4b45-c780-b6b2b9d243cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 6)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 7)) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 8)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 9)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 10)) (1.16.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 11)) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 12)) (0.24.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 13)) (4.67.1)\n",
            "Collecting protobuf<4.21.3 (from -r src/requirements.txt (line 14))\n",
            "  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 15)) (1.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 18)) (2.19.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 22)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 23)) (0.13.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 35)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r src/requirements.txt (line 36)) (5.9.5)\n",
            "Collecting thop (from -r src/requirements.txt (line 37))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->-r src/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->-r src/requirements.txt (line 9)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->-r src/requirements.txt (line 9)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->-r src/requirements.txt (line 9)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->-r src/requirements.txt (line 9)) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r src/requirements.txt (line 15)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r src/requirements.txt (line 15)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (3.10)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (3.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r src/requirements.txt (line 22)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r src/requirements.txt (line 22)) (2025.3)\n",
            "Collecting jedi>=0.16 (from ipython->-r src/requirements.txt (line 35))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->-r src/requirements.txt (line 35)) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->-r src/requirements.txt (line 35)) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->-r src/requirements.txt (line 35)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r src/requirements.txt (line 35)) (0.2.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch!=1.12.0,>=1.7.0->-r src/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r src/requirements.txt (line 18)) (3.0.3)\n",
            "Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, jedi, thop\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-speech 2.35.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-trace 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-appengine-logging 1.7.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.130.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-secret-manager 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-api-core 2.29.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-resource-manager 1.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-spanner 3.61.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-audit-log 0.4.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-discoveryengine 0.13.12 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-bigtable 2.35.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-dataproc 5.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 4.21.2 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.21.2 which is incompatible.\n",
            "googleapis-common-protos 1.72.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-functions 1.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-monitoring 2.28.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-language 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-translate 3.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-firestore 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jedi-0.19.2 protobuf-4.21.2 thop-0.1.1.post2209072238\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2c07d7871ae14f32a815244da97af7b2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r src/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Moxgo7w1zLXH"
      },
      "source": [
        "# Download the dataset\n",
        "Run the **getFlickr.sh** file to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMenanSHzLXH",
        "outputId": "303677d1-029e-49e8-d500-9c71cad8acd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-16 13:30:35--  http://image.ntua.gr/iva/datasets/flickr_logos/flickr_logos_27_dataset.tar.gz\n",
            "Resolving image.ntua.gr (image.ntua.gr)... 147.102.11.1\n",
            "Connecting to image.ntua.gr (image.ntua.gr)|147.102.11.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101827904 (97M) [application/x-gzip]\n",
            "Saving to: ‘data/flickr_logos_27_dataset.tar.gz’\n",
            "\n",
            "flickr_logos_27_dat 100%[===================>]  97.11M  18.7MB/s    in 12s     \n",
            "\n",
            "2026-01-16 13:30:48 (7.87 MB/s) - ‘data/flickr_logos_27_dataset.tar.gz’ saved [101827904/101827904]\n",
            "\n",
            "flickr_logos_27_dataset/\n",
            "flickr_logos_27_dataset/flickr_logos_27_dataset_distractor_set_urls.txt\n",
            "flickr_logos_27_dataset/flickr_logos_27_dataset_training_set_annotation.txt\n",
            "flickr_logos_27_dataset/flickr_logos_27_dataset_query_set_annotation.txt\n",
            "flickr_logos_27_dataset/flickr_logos_27_dataset_images.tar.gz\n",
            "tar (child): data/flickr_logos_27_dataset/flickr_logos_27_dataset_images.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "!sh data/getFlickr.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWI7-T8mzLXI"
      },
      "source": [
        "# Prepare data\n",
        "We nee to convert data to YOLO format.Now that we have our dataset, we need to convert the annotations into the format expected by YOLOv7. YOLOv7 expects data to be organized in a specific way, otherwise it is unable to parse through the directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTwSdTZ-zLXI",
        "outputId": "51fd3ef7-beba-486e-828c-ae618b9e175e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 1079/1079 [00:05<00:00, 182.23it/s]\n"
          ]
        }
      ],
      "source": [
        "!python src/convert_annotations.py --dataset flickr27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR19gTtdzLXI"
      },
      "source": [
        "To see if the conversion is correct, run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3GlEkrrzLXI",
        "outputId": "49fb6c45-1e75-4580-c186-2d89e8d2b5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 1079/1079 [00:03<00:00, 273.28it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7-logo/src/convert_annotations.py\", line 246, in <module>\n",
            "    main()\n",
            "  File \"/content/yolov7-logo/src/convert_annotations.py\", line 236, in main\n",
            "    assert os.path.exists(image_file)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n"
          ]
        }
      ],
      "source": [
        "!python src/convert_annotations.py --dataset flickr27 --plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e321c43f",
        "outputId": "f38a81fb-dc31-4b00-973f-6c19267784c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile src/convert_annotations.py\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import argparse\n",
        "import re\n",
        "import cv2 # Added cv2 for image operations in main function\n",
        "\n",
        "def get_class_names_logodet(path):\n",
        "    classes = {}\n",
        "    class_number = 0\n",
        "    for folder in glob(path + '/*/', recursive = True):\n",
        "        for subfolder in glob(folder + '/*/', recursive = True):\n",
        "            class_name = subfolder.split('/')[-2]\n",
        "            classes[class_name] = class_number\n",
        "            class_number += 1\n",
        "    return classes\n",
        "\n",
        "def get_class_names_yaml_logodet(path):\n",
        "    classes = []\n",
        "    for folder in glob(path + '/*/', recursive = True):\n",
        "        for subfolder in glob(folder + '/*/', recursive = True):\n",
        "            classes.append(subfolder.split('/')[-2])\n",
        "    return classes\n",
        "\n",
        "def get_annotations_logodet(path):\n",
        "    annotations = []\n",
        "    for folder in glob(path + '/*/', recursive = True):\n",
        "        for subfolder in glob(folder + '/*/', recursive = True):\n",
        "            for xml in glob(subfolder + '*.xml'):\n",
        "                annotations.append(xml)\n",
        "    return annotations\n",
        "\n",
        "def get_class_names(path):\n",
        "    classes = {}\n",
        "    class_number = -1\n",
        "    current_class = ''\n",
        "    with open(path) as f:\n",
        "        lines = f.readlines()\n",
        "        class_name = ''\n",
        "        for line in lines:\n",
        "            class_name = str(line.split(' ')[1])\n",
        "\n",
        "            if current_class != class_name:\n",
        "                class_number += 1\n",
        "            classes[class_name] = class_number\n",
        "            current_class = class_name\n",
        "    return classes\n",
        "\n",
        "def get_image_paths(path):\n",
        "    annotations = []\n",
        "    for image in glob(path + '/*.jpg'):\n",
        "        annotations.append(image)\n",
        "    return annotations\n",
        "\n",
        "def extract_info_from_annotations(line):\n",
        "    class_name = str(line.split(' ')[1])\n",
        "    xmin = int(line.split(' ')[3])\n",
        "    ymin = int(line.split(' ')[4])\n",
        "    xmax = int(line.split(' ')[5])\n",
        "    ymax = int(line.split(' ')[6])\n",
        "\n",
        "    # This function is incomplete in user provided code, but it's not the source of error.\n",
        "    # It probably returns these values, so keeping it consistent.\n",
        "    return class_name, xmin, ymin, xmax, ymax\n",
        "\n",
        "# The main function and helper for YOLO conversion, deduced from previous context\n",
        "def convert_bbox_coco_to_yolo(img_width, img_height, x_min, y_min, w, h):\n",
        "    x_center = (x_min + w / 2) / img_width\n",
        "    y_center = (y_min + h / 2) / img_height\n",
        "    w_normalized = w / img_width\n",
        "    h_normalized = h / img_height\n",
        "    return x_center, y_center, w_normalized, h_normalized\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Convert annotations to YOLO format and visualize them.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--dataset\",\n",
        "        type=str,\n",
        "        default=\"flickr27\",\n",
        "        help=\"Dataset name (e.g., 'flickr27').\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--plot\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Plot bounding boxes on images and save them.\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    dataset_path = os.path.join(\"data\", args.dataset)\n",
        "    image_path = os.path.join(dataset_path, \"images\")\n",
        "    yolo_labels_path = os.path.join(dataset_path, \"labels\")\n",
        "    os.makedirs(yolo_labels_path, exist_ok=True)\n",
        "\n",
        "    train_annotation_file = os.path.join(\n",
        "        dataset_path, f\"{args.dataset}_training_set_annotation.txt\"\n",
        "    )\n",
        "    query_annotation_file = os.path.join(\n",
        "        dataset_path, f\"{args.dataset}_query_set_annotation.txt\"\n",
        "    )\n",
        "\n",
        "    all_annotations = {}\n",
        "\n",
        "    # Process training annotations\n",
        "    # Fix: Added encoding='latin-1'\n",
        "    with open(train_annotation_file, \"r\", encoding='latin-1') as file:\n",
        "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
        "    for annotation_line in tqdm(annotation_list, desc=\"Processing Training Annotations\"):\n",
        "        parts = annotation_line.split(\" \")\n",
        "        img_filename = parts[0]\n",
        "        class_label = int(parts[1])\n",
        "        x_min, y_min, x_max, y_max = map(int, parts[2:6])\n",
        "\n",
        "        if img_filename not in all_annotations:\n",
        "            all_annotations[img_filename] = []\n",
        "        all_annotations[img_filename].append((class_label, x_min, y_min, x_max, y_max))\n",
        "\n",
        "    # Process query annotations\n",
        "    # Fix: Added encoding='latin-1'\n",
        "    with open(query_annotation_file, \"r\", encoding='latin-1') as file:\n",
        "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
        "    for annotation_line in tqdm(annotation_list, desc=\"Processing Query Annotations\"):\n",
        "        parts = annotation_line.split(\" \")\n",
        "        img_filename = parts[0]\n",
        "        class_label = int(parts[1])\n",
        "        x_min, y_min, x_max, y_max = map(int, parts[2:6])\n",
        "\n",
        "        if img_filename not in all_annotations:\n",
        "            all_annotations[img_filename] = []\n",
        "        all_annotations[img_filename].append((class_label, x_min, y_min, x_max, y_max))\n",
        "\n",
        "    for img_filename, annotations in tqdm(all_annotations.items(), desc=\"Converting to YOLO and Plotting\"):\n",
        "        try:\n",
        "            img_path = os.path.join(image_path, img_filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Warning: Could not read image {img_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            img_height, img_width, _ = img.shape\n",
        "\n",
        "            label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
        "            label_filepath = os.path.join(yolo_labels_path, label_filename)\n",
        "\n",
        "            with open(label_filepath, \"w\") as f:\n",
        "                for class_label, x_min, y_min, x_max, y_max in annotations:\n",
        "                    w = x_max - x_min\n",
        "                    h = y_max - y_min\n",
        "                    x_center, y_center, w_normalized, h_normalized = \\\n",
        "                        convert_bbox_coco_to_yolo(img_width, img_height, x_min, y_min, w, h)\n",
        "                    f.write(f\"{class_label} {x_center:.6f} {y_center:.6f} {w_normalized:.6f} {h_normalized:.6f}\\n\")\n",
        "\n",
        "            if args.plot:\n",
        "                plot_img_path = os.path.join(dataset_path, \"plots\", img_filename)\n",
        "                os.makedirs(os.path.dirname(plot_img_path), exist_ok=True)\n",
        "                img_copy = img.copy()\n",
        "                for class_label, x_min, y_min, x_max, y_max in annotations:\n",
        "                    cv2.rectangle(img_copy, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "                    cv2.putText(img_copy, str(class_label), (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "                cv2.imwrite(plot_img_path, img_copy)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_filename}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/convert_annotations.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2UtGV7kzLXI"
      },
      "source": [
        "Then, split data into sets.Next, we need to partition the dataset into train, validation, and test sets. These will contain 80%, 10%, and 10% of the data, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9km1xU0zLXI",
        "outputId": "29697589-44d2-44d5-9840-dcd93fcca723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7-logo/src/prepare_data.py\", line 95, in <module>\n",
            "    main()\n",
            "  File \"/content/yolov7-logo/src/prepare_data.py\", line 69, in main\n",
            "    train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
            "                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\", line 2851, in train_test_split\n",
            "    n_train, n_test = _validate_shuffle_split(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\", line 2481, in _validate_shuffle_split\n",
            "    raise ValueError(\n",
            "ValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n"
          ]
        }
      ],
      "source": [
        "!python src/prepare_data.py --dataset flickr27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WgGyOY_zLXJ"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyLMtzu_zLXJ"
      },
      "source": [
        "If you want to use the GPU, there is some changes code before start this code, otherwise it will be error when executed.\n",
        "\n",
        "Add on ```yolov7/utils/loss.py```\n",
        "\n",
        "change @ line 685\n",
        "```\n",
        "from_which_layer.append((torch.ones(size=(len(b),)) * i).to('cuda'))\n",
        "```\n",
        "\n",
        "add code @ line 757\n",
        "```\n",
        "fg_mask_inboxes = fg_mask_inboxes.to(torch.device('cuda'))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NURDilUUzLXJ",
        "outputId": "486c87c9-69d6-47cb-c91f-7aa3cbc5ca9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-16 13:31:00.618515: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-16 13:31:00.623227: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-16 13:31:00.638294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768570260.664485    1542 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768570260.671697    1542 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768570260.692190    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768570260.692253    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768570260.692257    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768570260.692264    1542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-16 13:31:00.697712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7-logo/src/yolov7/train.py\", line 595, in <module>\n",
            "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov7-logo/src/yolov7/utils/torch_utils.py\", line 71, in select_device\n",
            "    assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: CUDA unavailable, invalid device 0 requested\n"
          ]
        }
      ],
      "source": [
        "!python src/yolov7/train.py --img-size 640 --cfg src/cfg/training/yolov7.yaml --hyp data/hyp.scratch.yaml --batch 2 --epoch 300 --data data/logo_data_flickr.yaml --weights src/yolov7_training.pt --workers 2 --name yolo_logo_det --device 0"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4e544488b3cc811f146854d12104db46b548b29e04f8518cda87e1d805757d9"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}